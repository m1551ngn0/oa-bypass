use crate::{error::AppError, state::AppState, utils::create_client_from_headers};
use async_openai::types::chat::{CreateChatCompletionRequest, CreateChatCompletionResponse};
use async_openai::types::completions::{CreateCompletionRequest, CreateCompletionResponse};
use axum::{extract::State, http::HeaderMap, Json};
use std::sync::Arc;
use tracing::{error, info};

pub async fn chat_completions(
    State(_state): State<Arc<AppState>>,
    headers: HeaderMap,
    Json(request): Json<CreateChatCompletionRequest>,
) -> Result<Json<CreateChatCompletionResponse>, AppError> {
    info!("üí¨ Chat completion request: model={}", request.model);

    // –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞ –∏–∑ Authorization –∑–∞–≥–æ–ª–æ–≤–∫–∞
    let client = create_client_from_headers(&headers, false)?;

    let response = client
        .chat()
        .create(request)
        .await
        .map_err(|e| {
            error!("‚ùå Chat completion error: {}", e);
            AppError(format!("Chat completion error: {}", e))
        })?;

    info!("‚úÖ Chat completion —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω");
    Ok(Json(response))
}

pub async fn completions(
    State(_state): State<Arc<AppState>>,
    headers: HeaderMap,
    Json(request): Json<CreateCompletionRequest>,
) -> Result<Json<CreateCompletionResponse>, AppError> {
    info!("üìù Text completion request: model={}", request.model);

    // –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞ –∏–∑ Authorization –∑–∞–≥–æ–ª–æ–≤–∫–∞
    let client = create_client_from_headers(&headers, false)?;

    let response = client
        .completions()
        .create(request)
        .await
        .map_err(|e| {
            error!("‚ùå Text completion error: {}", e);
            AppError(format!("Text completion error: {}", e))
        })?;

    info!("‚úÖ Text completion —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω");
    Ok(Json(response))
}
